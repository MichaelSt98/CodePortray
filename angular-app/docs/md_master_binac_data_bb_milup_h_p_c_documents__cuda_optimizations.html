<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
	<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
	<meta http-equiv="X-UA-Compatible" content="IE=9"/>
	<meta name="generator" content="Doxygen 1.9.3"/>
	<meta name="viewport" content="width=device-width, initial-scale=1"/>
	<title>milupHPC: Cuda Optimizations</title>
	<link href="tabs.css" rel="stylesheet" type="text/css"/>
	<script type="text/javascript" src="jquery.js"></script>
	<script type="text/javascript" src="dynsections.js"></script>
	<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
	<link href="doxygen-custom.css" rel="stylesheet" type="text/css" />
	<!-- Add icon library -->
	<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
	<!-- Add font awesome icons -->
</head>
<body>
	<div id="banner">
		<div class="logo">
			<span class="subtitle">
				milupHPC documentation <!-- Cuda Optimizations -->
			</span>
			<!-- <span class="search">
				<input type="text" placeholder="Search" onkeydown="search(this,event);">
			</span> -->
		</div>
	<div class="icon-bar">
		<a href="https://www.tat.physik.uni-tuebingen.de/~schaefer/#codes" class="fa fa-university"></a>
		<a href="https://github.com/MichaelSt98/milupHPC" class="fa fa-github"></a>
		<a href="https://en.wikipedia.org/wiki/Smoothed-particle_hydrodynamics" class="fa fa-wikipedia-w"></a>
	</div>
	</div>
	<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<!-- Generated by Doxygen 1.9.3 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search",'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div><div class="header">
  <div class="headertitle"><div class="title">Cuda Optimizations </div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><hr  />
<ul>
<li>400 ms</li>
<li><hr  />
</li>
<li>Resources<ul>
<li><a href="https://www.youtube.com/watch?v=b8ESCws3_1s&amp;t=56s">CoffeeBeforeArch: CUDA Crash Course: GPU Performance Optimizations Part 1</a></li>
<li><a href="https://on-demand.gputechconf.com/gtc/2017/presentation/s7122-stephen-jones-cuda-optimization-tips-tricks-and-techniques.pdf">NVIDIA: CUDA OPTIMIZATION TIPS, TRICKS AND TECHNIQUES</a></li>
</ul>
</li>
</ul>
<h1><a class="anchor" id="autotoc_md91"></a>
Generally</h1>
<ul>
<li>avoid global memory read/write<ul>
<li>utitilize/abuse L1 cache</li>
</ul>
</li>
<li>avoid thread divergence</li>
<li>avoid thread synchronization</li>
<li>thread Block should be a multiple of number of SMs</li>
<li>pin memory</li>
<li><b>streams and concurrency</b><ul>
<li>overlap copy and computing</li>
</ul>
</li>
</ul>
<h1><a class="anchor" id="autotoc_md92"></a>
Temporary variables</h1>
<ul>
<li>Caching variables which are updated/read frequently (e.g. within loop)<ul>
<li>to possibly hit L1 cache</li>
<li>to reduce global memory read/write</li>
</ul>
</li>
</ul>
<p >e.g.:</p>
<div class="fragment"><div class="line"><span class="keywordflow">for</span> (<span class="keywordtype">int</span> i=0; i&lt;N; i++) {</div>
<div class="line">        tmp += a[row * N + i] * b[i * N + col];</div>
<div class="line">}</div>
<div class="line">c[row * N + col] = tmp;</div>
</div><!-- fragment --><p >instead of</p>
<div class="fragment"><div class="line"><span class="keywordflow">for</span> (<span class="keywordtype">int</span> i=0; i&lt;N; i++) {</div>
<div class="line">        c[row * N + col] += a[row * N + i] * b[i * N + col];</div>
<div class="line">}</div>
</div><!-- fragment --><p ><details>
 <summary>Code sample</summary></details>
</p>
<p ><details>
</p><div class="fragment"><div class="line">__global__ <span class="keywordtype">void</span> matrixMul(<span class="keyword">const</span> <span class="keywordtype">int</span> *a, <span class="keyword">const</span> <span class="keywordtype">int</span> *b, <span class="keywordtype">int</span> *c, <span class="keywordtype">int</span> N) {</div>
<div class="line">  <span class="comment">// Compute each thread&#39;s global row and column index</span></div>
<div class="line">  <span class="keywordtype">int</span> row = blockIdx.y * blockDim.y + threadIdx.y;</div>
<div class="line">  <span class="keywordtype">int</span> col = blockIdx.x * blockDim.x + threadIdx.x;</div>
<div class="line"> </div>
<div class="line">  <span class="comment">// Iterate over row, and down column</span></div>
<div class="line">  c[row * N + col] = 0;</div>
<div class="line">  <span class="keywordflow">for</span> (<span class="keywordtype">int</span> k = 0; k &lt; N; k++) {</div>
<div class="line">    <span class="comment">// Accumulate results for a single element</span></div>
<div class="line">    c[row * N + col] += a[row * N + k] * b[k * N + col];</div>
<div class="line">  }</div>
<div class="line">}</div>
<div class="line"> </div>
<div class="line">matrixMul&lt;&lt;&lt;blocks, threads&gt;&gt;&gt;(d_a, d_b, d_c, N);</div>
</div><!-- fragment --><p></details>
</p>
<p ><details>
</details>
 <br  />
</p>
<h1><a class="anchor" id="autotoc_md93"></a>
Coalesced access</h1>
<ul>
<li>Reduce request(s) from (global) memory by aligning arrays</li>
</ul>
<h1><a class="anchor" id="autotoc_md94"></a>
Prefetching data</h1>
<ul>
<li>prefetch data to allow coalesced global memory read</li>
</ul>
<p >e.g.:</p>
<div class="fragment"><div class="line"><span class="keywordflow">for</span> (<span class="keywordtype">int</span> i=0; i&lt;N; i+= 4) {</div>
<div class="line">        int4 a_tmp = <span class="keyword">reinterpret_cast&lt;</span>int4*<span class="keyword">&gt;</span>(&amp;a[row * N + i][0]);</div>
<div class="line">        </div>
<div class="line">        tmp += a_tmp.x * b[i * N + col];</div>
<div class="line">        tmp += a_tmp.y * b[(i + 1) * N + col];</div>
<div class="line">        tmp += a_tmp.z * b[(i + 2) * N + col];</div>
<div class="line">        tmp += a_tmp.w * b[(i + 3) * N + col];</div>
<div class="line">}</div>
</div><!-- fragment --><h1><a class="anchor" id="autotoc_md95"></a>
Unrolling</h1>
<ul>
<li>compiler explicitly unrolls loop in order to reduce loop overhead</li>
</ul>
<p >e.g.:</p>
<div class="fragment"><div class="line"><span class="preprocessor">#pragma unroll</span></div>
<div class="line"><span class="keywordflow">for</span> (<span class="keywordtype">int</span> i=0; i&lt;N; i+= 4) {</div>
<div class="line">        int4 a_tmp = <span class="keyword">reinterpret_cast&lt;</span>int4*<span class="keyword">&gt;</span>(&amp;a[row * N + i][0]);</div>
<div class="line">        </div>
<div class="line">        tmp += a_tmp.x * b[i * N + col];</div>
<div class="line">        tmp += a_tmp.y * b[(i + 1) * N + col];</div>
<div class="line">        tmp += a_tmp.z * b[(i + 2) * N + col];</div>
<div class="line">        tmp += a_tmp.w * b[(i + 3) * N + col];</div>
<div class="line">}</div>
</div><!-- fragment --><h1><a class="anchor" id="autotoc_md96"></a>
Shared/Tiled memory</h1>
<ul>
<li><b>Idea:</b> guarantee something is in the cache in order to have fewer related stalls</li>
<li><b>Solution:</b> Shared memory<ul>
<li>User-managed L1-cache</li>
<li>Private per-threadblock</li>
</ul>
</li>
<li>it is possibly necessary to batch data in order to fit into L1 cache</li>
</ul>
<p ><details>
 <summary>Code sample</summary></details>
</p>
<p ><details>
</p><div class="fragment"><div class="line">__global__ <span class="keywordtype">void</span> matrixMul(<span class="keyword">const</span> <span class="keywordtype">int</span> *a, <span class="keyword">const</span> <span class="keywordtype">int</span> *b, <span class="keywordtype">int</span> *c) {</div>
<div class="line">  <span class="comment">// Compute each thread&#39;s global row and column index</span></div>
<div class="line">  <span class="keywordtype">int</span> row = blockIdx.y * blockDim.y + threadIdx.y;</div>
<div class="line">  <span class="keywordtype">int</span> col = blockIdx.x * blockDim.x + threadIdx.x;</div>
<div class="line"> </div>
<div class="line">  <span class="comment">// Statically allocated shared memory</span></div>
<div class="line">  __shared__ <span class="keywordtype">int</span> s_a[SHMEM_SIZE];</div>
<div class="line">  __shared__ <span class="keywordtype">int</span> s_b[SHMEM_SIZE];</div>
<div class="line"> </div>
<div class="line">  <span class="comment">// Accumulate in temporary variable</span></div>
<div class="line">  <span class="keywordtype">int</span> tmp = 0;</div>
<div class="line"> </div>
<div class="line">  <span class="comment">// Sweep tile across matrix</span></div>
<div class="line">  <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 0; i &lt; N; i += blockDim.x) {</div>
<div class="line">    <span class="comment">// Load in elements for this tile</span></div>
<div class="line">    s_a[threadIdx.y * blockDim.x + threadIdx.x] = a[row * N + i + threadIdx.x];</div>
<div class="line">    s_b[threadIdx.y * blockDim.x + threadIdx.x] =</div>
<div class="line">        b[i * N + threadIdx.y * N + col];</div>
<div class="line"> </div>
<div class="line">    <span class="comment">// Wait for both tiles to be loaded in before doing computation</span></div>
<div class="line">    __syncthreads();</div>
<div class="line"> </div>
<div class="line">    <span class="comment">// Do matrix multiplication on the small matrix</span></div>
<div class="line">    <span class="keywordflow">for</span> (<span class="keywordtype">int</span> j = 0; j &lt; blockDim.x; j++) {</div>
<div class="line">      tmp +=</div>
<div class="line">          s_a[threadIdx.y * blockDim.x + j] * s_b[j * blockDim.x + threadIdx.x];</div>
<div class="line">    }</div>
<div class="line"> </div>
<div class="line">    <span class="comment">// Wait for all threads to finish using current tiles before loading in new</span></div>
<div class="line">    <span class="comment">// ones</span></div>
<div class="line">    __syncthreads();</div>
<div class="line">  }</div>
<div class="line"> </div>
<div class="line">  <span class="comment">// Write back results</span></div>
<div class="line">  c[row * N + col] = tmp;</div>
<div class="line">}</div>
<div class="line"> </div>
<div class="line">...</div>
<div class="line">matrixMul&lt;&lt;&lt;blocks, threads&gt;&gt;&gt;(d_a, d_b, d_c);</div>
<div class="line">...</div>
</div><!-- fragment --><p></details>
</p>
<p ><details>
</details>
 <br  />
 </p>
</div></div><!-- contents -->
</div><!-- PageDoc -->
<!-- start footer part -->
  <hr class="footer"/><address class="footer"><small>
    milupHPC  - Cuda Optimizations<br />
    Generated on Tue Jan 11 2022 17:43:18 by <a href="http://www.doxygen.org/index.html">Doxygen</a> 1.9.3
  </small></address>
</body>
</html>